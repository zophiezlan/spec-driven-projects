# NUAA Kit Glossary

Status: DRAFT

This glossary standardizes terms used across NUAA program design, evaluation, reporting, and funding documents.

## Peer Worker

An individual with lived experience relevant to the program focus who is engaged (remunerated) to design, deliver, or evaluate services. Peer workers bring trust, credibility, cultural knowledge, and practical insight that improves program relevance and effectiveness.

## Consumer Advisory (Group / Panel)

Structured group of people with lived experience who provide guidance on program design, implementation, evaluation, and reporting. Advisory participation is intentional, documented, and remunerated. Distinct from general consultation or ad‑hoc feedback.

## Remuneration

Fair monetary (or voucher) payment recognising the time, expertise, and intellectual labor of peer workers, advisors, and participants. NUAA baseline reference: $300 per structured session / meeting (adjust subject to funding agreements, award rates, and equity considerations).

## Harm Reduction

Evidence-based, rights-affirming approach that reduces adverse health, social, and legal impacts associated with drug use without requiring abstinence. Principles: pragmatism, human rights, participant agency, non‑judgment, cultural safety.

## Cultural Safety

Environment and practice where people feel respected, empowered, and free from discrimination, stigma, or retraumatisation. Includes trauma-informed facilitation, inclusive language, acknowledgment of Aboriginal & Torres Strait Islander data sovereignty, and responsiveness to LGBTIQ+, CALD, disability, age, and gender diversity.

## Participatory Evaluation

Evaluation approach where people with lived experience co‑design questions, co‑collect data, co‑interpret findings, and co‑author outputs. Moves beyond token consultation to shared decision-making and ownership of knowledge production.

## Logic Model

Structured visual + narrative mapping showing causal pathway: Inputs → Activities → Outputs → Outcomes (short/medium/long) → Impact. Serves as design backbone and evaluation anchor; every indicator must map to at least one element.

## Indicator

A specific, measurable variable (quantitative or qualitative) that tracks change or performance at process, output, outcome, or impact level. SMART: Specific, Measurable, Achievable, Relevant, Time-bound.

## Outcome vs Impact

Outcome: Change experienced by participants or systems attributable (in part) to the program (often short or medium term). Impact: Broader, sustained change at population, systemic, or sector level influenced by multiple factors including the program.

## Equity Indicator

Metric assessing whether program access, experience, benefit, or outcome differs across demographic or priority groups (e.g., Aboriginal & Torres Strait Islander peoples, gender groups, LGBTIQ+, CALD communities). Guides adaptation to reduce inequities.

## Fidelity

Degree to which implementation matches the intended program design (planned dosage, content, sequence, staffing model). Low fidelity may explain weak outcomes; tracked via process indicators.

## Data Sovereignty (Aboriginal & Torres Strait Islander)

Right of Indigenous peoples to govern collection, ownership, access, and application of data relating to them. Requires culturally appropriate consent, governance, storage, interpretation, and benefit-sharing.

## Trauma-Informed Practice

Approach acknowledging prevalence and impact of trauma; prioritizes emotional/psychological safety, choice, transparency, collaboration, and empowerment. Avoids re‑traumatisation in program and evaluation activities.

## Most Significant Change (MSC)

Participatory qualitative evaluation technique where stakeholders collect and select stories of change considered most significant, surfacing diverse impact dimensions and values.

## Outcome Harvesting

Evaluation approach collecting evidence of what outcomes occurred and working backwards to infer contributions—useful in complex, non‑linear change contexts (advocacy, systems work).

## Attribution vs Contribution

Attribution: Degree to which an outcome can be causally assigned to a specific program. Contribution: Recognition that multiple factors influence outcomes; program is one important part of a broader change ecosystem.

## Data Minimisation

Practice of collecting only data necessary for defined evaluation purposes, reducing privacy risk, burden, and potential misuse.

## Informed Consent

Process ensuring participants understand purpose, methods, risks, benefits, voluntary nature, confidentiality protections, and withdrawal rights before agreeing to participate.

## De-identification

Removal or transformation of direct and indirect identifiers to reduce likelihood that data can be linked back to individuals. Must be paired with governance to prevent re‑identification.

## Continuous Improvement Cycle

Structured iterative loop: Design → Implement → Measure → Reflect → Refine → (Re)Design. Ensures learning is operationalised rather than archived.

## Sustainability

Continuation or institutionalisation of beneficial outcomes and capabilities after initial funding or program period ends (e.g., integration into partner services, training-of-trainers models, policy adoption).

## Risk Register

Living document listing identified risks, likelihood, impact, mitigation actions, owners, and status. Supports proactive management and transparency in reporting.

## Remediation Action

Specific adaptation taken in response to measured weakness, risk escalation, or equity gap (e.g., adjust outreach method to improve CALD engagement). Logged for accountability and learning.

---

Next Steps:

- Peer review glossary with consumer advisory
- Validate remuneration references with finance/governance
- Tag glossary terms in templates (future enhancement)
